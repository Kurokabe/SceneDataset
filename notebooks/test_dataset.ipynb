{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scenedataset.scenedataset import SceneDataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import _transforms_video as video_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 13:51:00.417 | INFO     | scenedataset.scenedataset:_get_video_paths:448 - Found 1 videos\n"
     ]
    }
   ],
   "source": [
    "dataset = SceneDataset(paths = [\"/SceneDataset/data/02.mkv\"], show_progress=True, transform=transforms.Compose([video_transforms.ToTensorVideo(), transforms.Resize((128, 256))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-ignite\n",
      "  Downloading pytorch_ignite-0.4.10-py3-none-any.whl (264 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.1/264.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages (from pytorch-ignite) (23.0)\n",
      "Requirement already satisfied: torch<2,>=1.3 in /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages (from pytorch-ignite) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages (from torch<2,>=1.3->pytorch-ignite) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages (from torch<2,>=1.3->pytorch-ignite) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages (from torch<2,>=1.3->pytorch-ignite) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages (from torch<2,>=1.3->pytorch-ignite) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages (from torch<2,>=1.3->pytorch-ignite) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2,>=1.3->pytorch-ignite) (67.1.0)\n",
      "Requirement already satisfied: wheel in /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2,>=1.3->pytorch-ignite) (0.38.4)\n",
      "Installing collected packages: pytorch-ignite\n",
      "Successfully installed pytorch-ignite-0.4.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import (\n",
    "    MeanAbsoluteError,\n",
    "    MeanSquaredError,\n",
    "    StructuralSimilarityIndexMeasure,\n",
    ")\n",
    "mae = MeanAbsoluteError()\n",
    "mse = MeanSquaredError()\n",
    "ssim = StructuralSimilarityIndexMeasure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import SSIM, MeanSquaredError, FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssim = SSIM(data_range=1.0)\n",
    "# ssim = MeanSquaredError()\n",
    "fid = FID(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5703dcdf1345415c851ef5110a8637a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /root/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m next_frame \u001b[39m=\u001b[39m frames[j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m : j \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[1;32m     30\u001b[0m \u001b[39m# frames is between 0 and 1, scale between -1 and 1\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m difference \u001b[39m=\u001b[39m loss_fn_vgg(current_frame \u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, next_frame \u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     33\u001b[0m \u001b[39m# save_image(current_frame, f\"./images/current_frame_{i}_{j}.png\")\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# save_image(next_frame, f\"./images/next_frame_{i}_{j}.png\")\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# plt.imsave(f\"./images/current_frame_{i}_{j}.png\", current_frame[0].permute((1, 2, 0)).numpy())\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m# plt.imsave(f\"./images/next_frame_{i}_{j}.png\", next_frame[0].permute((1, 2, 0)).numpy())\u001b[39;00m\n\u001b[1;32m     37\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m))\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/lpips/lpips.py:119\u001b[0m, in \u001b[0;36mLPIPS.forward\u001b[0;34m(self, in0, in1, retPerLayer, normalize)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m# v0.0 - original release had a bug, where input was not scaled\u001b[39;00m\n\u001b[1;32m    118\u001b[0m in0_input, in1_input \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaling_layer(in0), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaling_layer(in1)) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m0.1\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m (in0, in1)\n\u001b[0;32m--> 119\u001b[0m outs0, outs1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet\u001b[39m.\u001b[39mforward(in0_input), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet\u001b[39m.\u001b[39;49mforward(in1_input)\n\u001b[1;32m    120\u001b[0m feats0, feats1, diffs \u001b[39m=\u001b[39m {}, {}, {}\n\u001b[1;32m    122\u001b[0m \u001b[39mfor\u001b[39;00m kk \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/lpips/pretrained_networks.py:129\u001b[0m, in \u001b[0;36mvgg16.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    127\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice4(h)\n\u001b[1;32m    128\u001b[0m h_relu4_3 \u001b[39m=\u001b[39m h\n\u001b[0;32m--> 129\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslice5(h)\n\u001b[1;32m    130\u001b[0m h_relu5_3 \u001b[39m=\u001b[39m h\n\u001b[1;32m    131\u001b[0m vgg_outputs \u001b[39m=\u001b[39m namedtuple(\u001b[39m\"\u001b[39m\u001b[39mVggOutputs\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mrelu1_2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu2_2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu3_3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu4_3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrelu5_3\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/scenedataset-mZH_Fr2s-py3.8/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "from ignite.engine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import lpips\n",
    "\n",
    "\n",
    "# def eval_step(engine, batch):\n",
    "#     return batch\n",
    "\n",
    "# default_evaluator = Engine(eval_step)\n",
    "\n",
    "# fid.attach(default_evaluator, 'fid')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "\n",
    "loss_fn_vgg = lpips.LPIPS(net='vgg')\n",
    "\n",
    "\n",
    "for i in range(0, len(dataset)):\n",
    "    frames = dataset[i]    \n",
    "    frames = frames.permute(1, 0, 2, 3)\n",
    "\n",
    "    for j in range(0, len(frames) - 1):\n",
    "        current_frame = frames[j : j + 1]\n",
    "        next_frame = frames[j + 1 : j + 2]\n",
    "        \n",
    "        # frames is between 0 and 1, scale between -1 and 1\n",
    "        difference = loss_fn_vgg(current_frame * 2 - 1, next_frame * 2 -1).item()\n",
    "\n",
    "        # save_image(current_frame, f\"./images/current_frame_{i}_{j}.png\")\n",
    "        # save_image(next_frame, f\"./images/next_frame_{i}_{j}.png\")\n",
    "        # plt.imsave(f\"./images/current_frame_{i}_{j}.png\", current_frame[0].permute((1, 2, 0)).numpy())\n",
    "        # plt.imsave(f\"./images/next_frame_{i}_{j}.png\", next_frame[0].permute((1, 2, 0)).numpy())\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        ax = fig.add_axes([0,0,1,1])\n",
    "        ax.imshow(current_frame[0].permute((1, 2, 0)).numpy())\n",
    "        ax.set_title(f\"fid: {difference}\")\n",
    "        plt.savefig(f\"./images/{difference:.5f}_current_frame_{i}_{j}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        ax = fig.add_axes([0,0,1,1])\n",
    "        ax.imshow(next_frame[0].permute((1, 2, 0)).numpy())\n",
    "        ax.set_title(f\"fid: {difference}\")\n",
    "        plt.savefig(f\"./images/{difference:.5f}_next_frame_{i}_{j}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1591198/2186432617.py:14: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f\"./images/{difference}_current_frame_{i}_{j}.png\"))\n",
      "/tmp/ipykernel_1591198/2186432617.py:15: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f\"./images/{difference}_next_frame_{i}_{j}.png\"))\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "filenames = glob(\"./images/*_current_frame_*.png\")\n",
    "\n",
    "for filename in filenames:\n",
    "    \n",
    "    try:\n",
    "        difference, i, j = re.findall(r\"(\\d+.\\d+)_current_frame_(\\d+)_(\\d+).png\", filename)[0]\n",
    "    except:\n",
    "        print(filename)\n",
    "    images = []\n",
    "    images.append(imageio.imread(f\"./images/{difference}_current_frame_{i}_{j}.png\"))\n",
    "    images.append(imageio.imread(f\"./images/{difference}_next_frame_{i}_{j}.png\"))\n",
    "    imageio.mimsave(f\"./video/{difference}_animation_{i}_{j}.gif\", images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 07:34:27.185 | INFO     | scenedataset.scenedataset:_get_video_paths:445 - Found 1 videos\n",
      "2023-02-07 07:34:27.193 | INFO     | scenedataset.scenedataset:retrieve_scenes_from_video:235 - Removing duplicate scenes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29054f44bb954cf59264232471407394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading scenes to find duplicates...:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344ed3292fbf40168bb2778627361e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading scenes to find duplicates...:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cb4070fca94af199dcd159a94b366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading scenes to find duplicates...:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "broken_dataset = SceneDataset(paths = [\"/SceneDataset/data/02.mkv\"], show_progress=True, min_max_len=(15, 25), duplicate_threshold=0.1, duplicate_method=\"ssim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scenedataset-mZH_Fr2s-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5d9115d08c17040944e5b7fbe5eb793d63549107852724990245c0de104487d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
